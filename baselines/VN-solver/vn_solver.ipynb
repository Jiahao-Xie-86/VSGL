{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cds/anaconda3/envs/vn_gan/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cds/anaconda3/envs/vn_gan/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/100: 100%|██████████| 8/8 [00:00<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.40%\n",
      "Epoch 1/100: Train Loss: 1.3613, Val Loss: 91.8199, Test Loss: 86.7780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 8/8 [00:00<00:00, 19.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.60%\n",
      "Epoch 2/100: Train Loss: 0.7457, Val Loss: 23.2389, Test Loss: 27.5171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 8/8 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 1\n",
      "Epoch 3/100: Train Loss: 0.5752, Val Loss: 18.7483, Test Loss: 22.1793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 8/8 [00:00<00:00, 19.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.65%\n",
      "Epoch 4/100: Train Loss: 0.5008, Val Loss: 12.9880, Test Loss: 19.7851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 8/8 [00:00<00:00, 19.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 1\n",
      "Epoch 5/100: Train Loss: 0.4623, Val Loss: 25.2851, Test Loss: 39.9106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 8/8 [00:00<00:00, 19.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.75%\n",
      "Epoch 6/100: Train Loss: 0.4574, Val Loss: 8.6668, Test Loss: 9.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 8/8 [00:00<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 1\n",
      "Epoch 7/100: Train Loss: 0.2989, Val Loss: 6.9745, Test Loss: 8.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 8/8 [00:00<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.80%\n",
      "Epoch 8/100: Train Loss: 0.1841, Val Loss: 4.2553, Test Loss: 7.5840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 8/8 [00:00<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.85%\n",
      "Epoch 9/100: Train Loss: 0.0648, Val Loss: 3.3203, Test Loss: 10.4796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 8/8 [00:00<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 1\n",
      "Epoch 10/100: Train Loss: 0.0762, Val Loss: 3.0570, Test Loss: 9.8209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 8/8 [00:00<00:00, 19.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 2\n",
      "Epoch 11/100: Train Loss: 0.1213, Val Loss: 7.7245, Test Loss: 15.3310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 8/8 [00:00<00:00, 19.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 3\n",
      "Epoch 12/100: Train Loss: 0.1366, Val Loss: 16.8222, Test Loss: 25.0387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 8/8 [00:00<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved with validation accuracy: 0.95%\n",
      "Epoch 13/100: Train Loss: 0.1403, Val Loss: 1.8212, Test Loss: 18.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 8/8 [00:00<00:00, 19.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 1\n",
      "Epoch 14/100: Train Loss: 0.2050, Val Loss: 14.4516, Test Loss: 12.9497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 8/8 [00:00<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 2\n",
      "Epoch 15/100: Train Loss: 0.3065, Val Loss: 12.9006, Test Loss: 14.6456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 8/8 [00:00<00:00, 19.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 3\n",
      "Epoch 16/100: Train Loss: 0.1981, Val Loss: 7.1498, Test Loss: 10.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 8/8 [00:00<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 4\n",
      "Epoch 17/100: Train Loss: 0.1972, Val Loss: 7.2137, Test Loss: 8.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 8/8 [00:00<00:00, 19.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 5\n",
      "Epoch 18/100: Train Loss: 0.0474, Val Loss: 4.9684, Test Loss: 9.3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 8/8 [00:00<00:00, 19.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 6\n",
      "Epoch 19/100: Train Loss: 0.0226, Val Loss: 4.0197, Test Loss: 9.3932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 8/8 [00:00<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 7\n",
      "Epoch 20/100: Train Loss: 0.0117, Val Loss: 3.4726, Test Loss: 9.5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 8/8 [00:00<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 8\n",
      "Epoch 21/100: Train Loss: 0.0345, Val Loss: 7.6141, Test Loss: 10.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 8/8 [00:00<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 9\n",
      "Epoch 22/100: Train Loss: 0.0222, Val Loss: 8.6798, Test Loss: 9.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 8/8 [00:00<00:00, 19.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs without improvement: 10\n",
      "Early stopping triggered.\n",
      "Training complete. Best model saved as best_resnet50_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(29)\n",
    "\n",
    "# Define paths to dataset directories\n",
    "hamiltonian_dir = '0p35_sp_uniform_color_spiral_hamiltonian_medium'\n",
    "non_hamiltonian_dir = '0p35_sp_uniform_color_spiral_non_hamiltonian_medium'\n",
    "\n",
    "# Define data transformations\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, label, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.label\n",
    "\n",
    "# Create datasets for each class\n",
    "hamiltonian_dataset = CustomImageDataset(hamiltonian_dir, label=1, transform=data_transforms)\n",
    "non_hamiltonian_dataset = CustomImageDataset(non_hamiltonian_dir, label=0, transform=data_transforms)\n",
    "\n",
    "# Combine datasets\n",
    "dataset = torch.utils.data.ConcatDataset([hamiltonian_dataset, non_hamiltonian_dataset])\n",
    "\n",
    "# Split dataset into training, validation, and test sets\n",
    "indices = list(range(len(dataset)))\n",
    "train_val_size = 100\n",
    "test_size = 500\n",
    "\n",
    "train_val_indices, test_indices = train_test_split(indices, test_size=test_size, stratify=[dataset[i][1] for i in indices], random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_val_indices[:train_val_size], test_size=0.2, stratify=[dataset[i][1] for i in train_val_indices[:train_val_size]], random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "# Initialize the ResNet-50 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Change the final layer for binary classification\n",
    "model = model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define function to compute metrics\n",
    "def compute_metrics(preds, labels):\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    return accuracy, f1\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return total_loss / len(dataloader), accuracy, f1\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, val_loader, test_loader, device, optimizer, criterion, num_epochs=100, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    best_accuracy = 0\n",
    "    early_stop_counter = 0\n",
    "    best_model_path = './best_resnet50_model.pth'\n",
    "    columns = ['epoch', 'train_loss', 'train_acc', 'train_f1', 'val_loss', 'val_acc', 'val_f1', 'test_loss', 'test_acc', 'test_f1']\n",
    "    results = []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch}/{num_epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        train_acc, train_f1 = compute_metrics(torch.tensor(all_preds), torch.tensor(all_labels))\n",
    "        train_loss /= total\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, device, criterion)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_acc > best_accuracy:\n",
    "            best_accuracy = val_acc\n",
    "            early_stop_counter = 0\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Best model saved with validation accuracy: {val_acc:.2f}%\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            print(f\"Epochs without improvement: {early_stop_counter}\")\n",
    "        \n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Test evaluation\n",
    "        test_loss, test_acc, test_f1 = evaluate(model, test_loader, device, criterion)\n",
    "\n",
    "        # Log results\n",
    "        results.append([epoch, train_loss, train_acc, train_f1, val_loss, val_acc, val_f1, test_loss, test_acc, test_f1])\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "        df.to_csv('resnet50_training_results.csv', index=False)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete. Best model saved as best_resnet50_model.pth\")\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, val_loader, test_loader, device, optimizer, criterion, num_epochs=100, patience=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vn_gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
